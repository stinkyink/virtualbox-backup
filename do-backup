#!/usr/bin/env ruby

require 'csv'
require 'fileutils'
require 'optparse'
require 'tmpdir'

require 'bundler/setup'
require 'fog'

trap :INT, :EXIT

SCRIPT_DIR = File.dirname(__FILE__)
CONFIG_FILE = SCRIPT_DIR + '/config.yaml'

CONFIG = YAML.load_file(CONFIG_FILE)

OUT_DIR = CONFIG['local']['out-dir']
SUDO = CONFIG['local']['use-sudo'] ? 'sudo' : ''

require_relative 'lib/helpers'

require_relative 'lib/virtual_machine'
require_relative 'lib/local_backup'
require_relative 'lib/offsite_backup'

require_relative 'lib/offsite_backends/backend'
require_relative 'lib/offsite_backends/glacier_backend'
require_relative 'lib/offsite_backends/s3_backend'
require_relative 'lib/offsite_backends/test_backend'

$options = OpenStruct.new
$options.do_local = true
$options.do_offsite = true
$options.quiet = false

OptionParser.new {|opts|
  opts.banner = "Usage: #{File.basename(__FILE__)} [options]"
  opts.separator ''
  opts.separator 'Options:'

  opts.on('-h', '--help', 'Show this message') do
    puts opts
    exit
  end
  opts.on('-q', '--quiet', 'Suppress output') do |v|
    $options.quiet = true
  end
  opts.on('-l', '--no-local', "Don't perform local backup") do |v|
    $options.do_local = false
  end
  opts.on('-o', '--no-offsite', "Don't perform off-site backup") do |v|
    $options.do_offsite = false
  end
}.parse!

class Tool
  include Helpers

  def self.run!
    if not Dir.exists?(OUT_DIR)
      fail "Output directory does not exist: #{OUT_DIR}"
    end

    virtual_machines = VirtualMachine.find(CONFIG['virtual-machines']['include'])
    @backups = virtual_machines.map {|vm| LocalBackup.new(vm) }

    do_local_backups!    if $options.do_local
    do_offsite_backups!  if $options.do_offsite
  rescue ProcessingError => e
    STDERR.puts "ERROR: #{e.message}"
    exit 1
  end

  private

  def self.do_local_backups!
    @backups.each(&:do_backup!)
    consolidate_new_dirs!
    rotate_backups!
  end

  def self.do_offsite_backups!
    exclude_offsite =
      VirtualMachine.find(CONFIG['virtual-machines']['offsite-exclude']).
        map(&:name)
    @backups.each do |backup|
      next  if exclude_offsite.include?(backup.virtual_machine.name)
      if backup.error?
        STDERR.puts "WARNING: #{backup.virtual_machine}: Skipping offsite backup " +
                    "due to previous errors."
        next
      end
      offsite_backup =
        OffsiteBackup.new(backup.completed_backup_dirs.first,
                          backup.virtual_machine.name, backup.time)
      offsite_backup.push!
      offsite_backup.remove_old!
    end
  end

  def self.rotate_backups!
    dirs_by_type = Hash.new
    Dir.glob(OUT_DIR + '/*/').each do |dir|
      matches = /^\d-([a-z]+)/.match(File.basename(dir))
      type = matches[1]
      (dirs_by_type[type] ||= Array.new) << dir
    end

    return  if dirs_by_type['new'].nil?

    moving_up = dirs_by_type['new'].sort_by {|x| dir_date(x) }
    intervals = {
      daily:     1,
      weekly:    7,
      monthly:  30,
      yearly:  365
    }
    %w(daily weekly monthly yearly).each_with_index do |type, type_index|
      dirs = (dirs_by_type[type] || Array.new).sort_by {|x| dir_date(x) }
      interval = intervals[type.to_sym]
      moving_up.each do |candidate|
        if dirs.empty? ||
           (dir_date(candidate) >= (dir_date(dirs.last) + interval))
          dirs << candidate
        else
          FileUtils.rm_rf(candidate)
        end
      end
      moving_up.clear
      max_dir_index = CONFIG['local']['rotate'][type[0..-2] + 'ies']
      digits = max_dir_index.to_s.length
      dirs.each_with_index do |dir, dir_index|
        new_index = dirs.count - dir_index
        if new_index >= (max_dir_index + 1)
          moving_up << dir
        else
          date = File.basename(dir).split('_').last
          new_dir =
            OUT_DIR +
            "/#{type_index + 1}-#{type}." +
            "#{new_index.to_s.rjust(digits, '0')}_#{date}/"
          unless dir == new_dir
            FileUtils.mv(dir, new_dir)
          end
        end
      end
    end

    moving_up.each do |dir|
      FileUtils.rm_rf(dir)
    end
  rescue Exception => e
    STDERR.puts "ERROR: Failed to rotate backups: #{e.message}"
  end

  # When backups take place across the day boundary, we can end up with multiple
  # "new" directories. This method consolidates these into a single directory,
  # containing the latest backup for each VM.
  def self.consolidate_new_dirs!
    new_dirs = Dir.glob(File.join(OUT_DIR, '0-new_*'))
    date = Time.now.strftime('%Y-%m-%d')
    target = File.join(OUT_DIR, "0-new_#{date}")
    new_dirs.sort_by {|x| dir_date(x) }.reverse.each do |dir|
      next  if dir == target
      Dir.glob(File.join(dir, '*')).each do |source|
        next  if Dir.exists?(File.join(target, File.basename(source)))
        FileUtils.mv(source, target)
      end
      FileUtils.rm_rf(dir)
    end
  end

  def self.dir_date(dir)
    Date.parse(dir.split('_').last)
  end
end

Tool.run!
